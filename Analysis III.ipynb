{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libaries\n",
    "%matplotlib qt5 \n",
    "\n",
    "import mne\n",
    "import os\n",
    "from mne.preprocessing import ICA\n",
    "from mne.preprocessing import create_eog_epochs, create_ecg_epochs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store significant sensors to this variable so don't remove \n",
    "sign_sensors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['382733.vhdr', '382733_2.vhdr', '477819.vhdr', '477819_2.vhdr', '554432.vhdr', '554432_2.vhdr', '884723.vhdr', '884723_2.vhdr', '928376.vhdr', '928376_2.vhdr', '990291.vhdr', '990291_2.vhdr']\n",
      "['382733.vhdr', '382733_2.vhdr']\n"
     ]
    }
   ],
   "source": [
    "vhdr_files = ['382733.vhdr', '382733_2.vhdr', '477819.vhdr', '477819_2.vhdr', '554432.vhdr', '554432_2.vhdr', '884723.vhdr', '884723_2.vhdr', '928376.vhdr', '928376_2.vhdr', '990291.vhdr', '990291_2.vhdr']\n",
    "print(vhdr_files)\n",
    "temp_list = vhdr_files[0:2]\n",
    "print(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382733.vhdr\n",
      "Reading data/epochs/processed_epochs/382733-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     700.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "<EpochsFIF  |   120 events (all good), -0.2 - 0.7 sec, baseline [-0.2, 0], ~26.5 MB, data loaded,\n",
      " 'Dislike Conf': 2\n",
      " 'Favourite Conf': 1\n",
      " 'Favourite Match': 1\n",
      " 'Finnish Conf': 24\n",
      " 'Finnish Match': 25\n",
      " 'Foreing Conf': 22\n",
      " 'Foreing Match': 27\n",
      " 'Neutrals': 10\n",
      " 'Unknowns': 8>\n"
     ]
    }
   ],
   "source": [
    "filename = temp_list[0]\n",
    "print(filename)\n",
    "\n",
    "if filename[6] == '.':\n",
    "    epochs_EN = mne.read_epochs('data/epochs/processed_epochs/' + filename[:6] + '-epo.fif')\n",
    "else:\n",
    "    epochs_EN = mne.read_epochs('data/epochs/processed_epochs/' + filename[:8] + '-epo.fif')\n",
    "print(epochs_EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382733_2.vhdr\n",
      "Reading data/epochs/processed_epochs/382733_2-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     700.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "<EpochsFIF  |   120 events (all good), -0.2 - 0.7 sec, baseline [-0.2, 0], ~26.5 MB, data loaded,\n",
      " 'Dislike Conf': 1\n",
      " 'Dislike Match': 1\n",
      " 'Favourite Conf': 1\n",
      " 'Favourite Match': 1\n",
      " 'Finnish Conf': 23\n",
      " 'Finnish Match': 27\n",
      " 'Foreing Conf': 25\n",
      " 'Foreing Match': 23\n",
      " 'Neutrals': 10\n",
      " 'Unknowns': 8>\n"
     ]
    }
   ],
   "source": [
    "filename = temp_list[1]\n",
    "print(filename)\n",
    "\n",
    "if filename[6] == '.':\n",
    "    epochs_FIN = mne.read_epochs('data/epochs/processed_epochs/' + filename[:6] + '-epo.fif')\n",
    "else:\n",
    "    epochs_FIN = mne.read_epochs('data/epochs/processed_epochs/' + filename[:8] + '-epo.fif')\n",
    "print(epochs_FIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Evoked  |  'Finnish Match' (mean, N=25), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Finnish Conf' (mean, N=24), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Foreing Match' (mean, N=27), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Foreing Conf' (mean, N=22), [-0.2, 0.7] sec, 32 ch, ~311 kB>]\n",
      "[<Evoked  |  'Finnish Match' (mean, N=27), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Finnish Conf' (mean, N=23), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Foreing Match' (mean, N=23), [-0.2, 0.7] sec, 32 ch, ~311 kB>, <Evoked  |  'Foreing Conf' (mean, N=25), [-0.2, 0.7] sec, 32 ch, ~311 kB>]\n"
     ]
    }
   ],
   "source": [
    "# Lets study Finnish Match / Conf and Foreing Match / Conf\n",
    "finmatc = epochs_EN['Finnish Match'].average()\n",
    "finconf = epochs_EN['Finnish Conf'].average()\n",
    "formatc = epochs_EN['Foreing Match'].average()\n",
    "forconf = epochs_EN['Foreing Conf'].average()\n",
    "\n",
    "all_evokeds_EN = [finmatc, finconf, formatc, forconf]\n",
    "\n",
    "finmatc = epochs_EN['Finnish Match']\n",
    "finconf = epochs_EN['Finnish Conf']\n",
    "formatc = epochs_EN['Foreing Match']\n",
    "forconf = epochs_EN['Foreing Conf']\n",
    "all_epochs_EN = [finmatc, finconf, formatc, forconf]\n",
    "print(all_evokeds_EN)\n",
    "\n",
    "# Lets study Finnish Match / Conf and Foreing Match / Conf\n",
    "finmatc = epochs_FIN['Finnish Match'].average()\n",
    "finconf = epochs_FIN['Finnish Conf'].average()\n",
    "formatc = epochs_FIN['Foreing Match'].average()\n",
    "forconf = epochs_FIN['Foreing Conf'].average()\n",
    "\n",
    "all_evokeds_FIN = [finmatc, finconf, formatc, forconf]\n",
    "\n",
    "finmatc = epochs_FIN['Finnish Match']\n",
    "finconf = epochs_FIN['Finnish Conf']\n",
    "formatc = epochs_FIN['Foreing Match']\n",
    "forconf = epochs_FIN['Foreing Conf']\n",
    "all_epochs_FIN = [finmatc, finconf, formatc, forconf]\n",
    "print(all_evokeds_FIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "Applying baseline correction (mode: mean)\n",
      "[8.23242863e-17]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "## The statistical analysis ###\n",
    "# WRITTEN: Ali Salloum 4.5.2019\n",
    "# Modified: Juho Aaltonen 5.5.2019\n",
    "\n",
    "# We compare the Global field power distributions\n",
    "\n",
    "FMAT_F = all_evokeds_FIN[0]\n",
    "FCON_F = all_evokeds_FIN[1]\n",
    "EMAT_F = all_evokeds_FIN[2]\n",
    "ECON_F = all_evokeds_FIN[3]\n",
    "\n",
    "FMAT_E = all_evokeds_EN[0]\n",
    "FCON_E = all_evokeds_EN[1]\n",
    "EMAT_E = all_evokeds_EN[2]\n",
    "ECON_E = all_evokeds_EN[3]\n",
    "\n",
    "all_evokeds_list = [FMAT_F, FCON_F, EMAT_F, ECON_F, FMAT_E, FCON_E, EMAT_E, ECON_E]\n",
    "\n",
    "# Preparing stuff\n",
    "gfp_list = []\n",
    "for term in all_evokeds_list:\n",
    "    temp = np.sum(term.data ** 2, axis=0)\n",
    "    gfp_list.append(mne.baseline.rescale(temp, term.times * 1e3, baseline=(None, 0)))\n",
    "\n",
    "\n",
    "# Crosscorrelation between two signals, should be very low\n",
    "cc = np.correlate(gfp_list[0], gfp_list[4], mode=\"valid\")\n",
    "print(cc)\n",
    "# Perform the Kolmogorov-Smirnov test for goodness of fit, skip this now\n",
    "\n",
    "plt.plot(all_evokeds_list[0].times * 1e3, gfp_list[0])\n",
    "plt.plot(all_evokeds_list[4].times * 1e3, gfp_list[4])\n",
    "plt.plot(all_evokeds_list[0].times * 1e3, gfp_list[1])\n",
    "plt.plot(all_evokeds_list[4].times * 1e3, gfp_list[5])\n",
    "plt.legend(('Finnish FMAT', 'English FMAT', 'Finnish FCON', 'English FCON'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping finished!\n"
     ]
    }
   ],
   "source": [
    "# Peforming the bootstrapping, I spoke about this method in our last meeting\n",
    "\n",
    "gfp_bootstrap = []\n",
    "for j in range(0,8):\n",
    "    gfp_bootstrap.append([])\n",
    "    for i in range(10000):\n",
    "        np.random.seed(i)\n",
    "        gfp_bootstrap[j].append((resample(gfp_list[j])))\n",
    "    gfp_bootstrap[j] = np.mean(gfp_bootstrap[j], axis=1)\n",
    "print('Bootstrapping finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Bootstrap 382733')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot bootstraps\n",
    "plt.hist(gfp_bootstrap[0],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[1],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[2],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[3],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[4],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[5],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[6],alpha = 0.5)\n",
    "plt.hist(gfp_bootstrap[7],alpha = 0.5)\n",
    "#plt.legend(('FMAT_F', 'FCON_F', 'EMAT_F', 'ECON_F', 'FMAT_E', 'FCON_E', 'EMAT_E', 'ECON_E'))\n",
    "plt.legend(('Finnish FMAT', 'Finnish FCON', 'Finnish FORMAT', 'Finnish FORCON', 'English FMAT', 'English FCON', 'English FORMAT', 'English FORCON'))\n",
    "plt.xlabel(\"Voltage (µV)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title('Bootstrap ' + filename[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This may take a while\n",
      "New term1 begins\n",
      "Half point of this term!\n",
      "1\n",
      "New term1 begins\n",
      "Half point of this term!\n",
      "2\n",
      "New term1 begins\n",
      "Half point of this term!\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "dif_bootstrap_means = []\n",
    "print('This may take a while')\n",
    "for term1 in gfp_list:\n",
    "    print('New term1 begins')\n",
    "    dif_bootstrap_means.append([])\n",
    "    k = 0\n",
    "    for term2 in gfp_list:\n",
    "        combined = np.concatenate((term1, term2), axis=0)\n",
    "        perms_temp1 = []\n",
    "        perms_temp2 = []\n",
    "        if k == 3:\n",
    "            print('Half point of this term!')\n",
    "        for i in range(10000):\n",
    "            np.random.seed(i)\n",
    "            perms_temp1.append(resample(combined, n_samples = len(term1)))\n",
    "            perms_temp2.append(resample(combined, n_samples = len(term2)))\n",
    "            \n",
    "        dif_bootstrap_means[j].append(np.mean(perms_temp1, axis=1)-np.mean(perms_temp2, axis=1))\n",
    "        k += 1 \n",
    "    j += 1\n",
    "    print(j)\n",
    "print('Bootstrap mean differences are now computed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "obs_difs = []\n",
    "p_value = []\n",
    "for term1 in gfp_list:\n",
    "    obs_difs.append([])\n",
    "    p_value.append([])\n",
    "    k = 0\n",
    "    for term2 in gfp_list:\n",
    "        obs_difs[j].append(np.mean(term1) - np.mean(term2))\n",
    "        p_value[j].append(dif_bootstrap_means[j][k][dif_bootstrap_means[j][k] >= obs_difs[j][k]].shape[0]/10000)\n",
    "        if j == k:\n",
    "            print(dif_bootstrap_means[j][k])\n",
    "            print(obs_difs[j][k])\n",
    "            print(p_value[j][k])\n",
    "        k += 1\n",
    "    j += 1\n",
    "print('observed differences and p-values are computed!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('P-values from bootstarping different test and stimuli sets. Subject: {:6s}'.format(filename[:6]))\n",
    "print('{:8} {:8s} {:8s} {:8s} {:8s} {:8s} {:8s} {:8s} {:8s}'.format('', 'FMAT_F', 'FCON_F', 'EMAT_F', 'ECON_F', 'FMAT_E', 'FCON_E', 'EMAT_E', 'ECON_E'))\n",
    "header = ['FMAT_F', 'FCON_F', 'EMAT_F', 'ECON_F', 'FMAT_E', 'FCON_E', 'EMAT_E', 'ECON_E']\n",
    "\n",
    "for i in range(0,8):\n",
    "    print('{:8s} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f}'.format(header[i],\n",
    "                                                                                                 p_value[i][0],p_value[i][1],p_value[i][2],p_value[i][3],\n",
    "                                                                                                p_value[i][4],p_value[i][5],p_value[i][6],p_value[i][7]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
