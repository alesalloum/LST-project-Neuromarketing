{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This processes raw data\n",
    "\n",
    "# Import relevant libaries\n",
    "%matplotlib qt5 \n",
    "\n",
    "import mne\n",
    "import os\n",
    "from mne.preprocessing import ICA\n",
    "from mne.preprocessing import create_eog_epochs, create_ecg_epochs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO THIS TO EACH RECORDING SEPARATELY\n",
    "\n",
    "# set data folder path\n",
    "eeg_path = os.path.join(os.getcwd(), 'raw_data')\n",
    "\n",
    "# list all vhdr files in eeg folder\n",
    "vhdr_files = [f for f in os.listdir(eeg_path) if f.endswith('.vhdr')]\n",
    "vhdr_files.sort()\n",
    "print(vhdr_files)\n",
    "\n",
    "# Select one of the study subjects (=vhdr_files)\n",
    "filename = vhdr_files[0]\n",
    "\n",
    "# List known noisy channels here\n",
    "noisy_channels = []\n",
    "\n",
    "# Get data drom the opinion test\n",
    "response_path = os.path.join(os.getcwd(), 'keyboard_opinion')\n",
    "response_file = [f for f in os.listdir(response_path) if f.startswith(filename[:6])]\n",
    "response = response_file[0]\n",
    "filename, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data, set montage and plot. Also click bad channels.\n",
    "\n",
    "raw = mne.io.read_raw_brainvision(os.path.join(eeg_path, filename), stim_channel=True, preload=True, eog = ('EOG1', 'EOG2','EOG3','EOG4'))\n",
    "print('Data downloaded')\n",
    "\n",
    "montage = mne.channels.read_montage(\"standard_1020\")\n",
    "raw.set_montage(montage)\n",
    "print('Montage set')\n",
    "\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the data\n",
    "\n",
    "events = mne.find_events(raw, stim_channel = 'STI 014')\n",
    "event_times = events[:,0]\n",
    "\n",
    "raw1 = raw.copy().crop((event_times[0]/1000)-20, (event_times[19]/1000)+10)\n",
    "raw2 = raw.copy().crop((event_times[20]/1000)-10, (event_times[39]/1000)+10)\n",
    "raw3 = raw.copy().crop((event_times[40]/1000)-10, (event_times[59]/1000)+10)\n",
    "raw4 = raw.copy().crop((event_times[60]/1000)-10, (event_times[79]/1000)+10)\n",
    "raw5 = raw.copy().crop((event_times[80]/1000)-10, (event_times[99]/1000)+10)\n",
    "raw6 = raw.copy().crop((event_times[100]/1000)-10, (event_times[119]/1000)+10)\n",
    "\n",
    "raw1.append([raw2, raw3, raw4, raw5, raw6])\n",
    "raw = raw1\n",
    "del raw1, raw2, raw3, raw4, raw5, raw6\n",
    "\n",
    "raw.plot()\n",
    "\n",
    "# Filter the data\n",
    "raw.filter(1, 40., fir_design='firwin')\n",
    "\n",
    "# Interpolate bad channels\n",
    "raw = raw.interpolate_bads(reset_bads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT ICA\n",
    "\n",
    "# Set the parameters\n",
    "n_components = 25\n",
    "method = 'fastica'\n",
    "decim = 3 \n",
    "random_state = 23\n",
    "\n",
    "# Run the analysis\n",
    "ica = ICA(n_components=n_components, method=method, random_state=random_state)\n",
    "reject = None\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False)\n",
    "\n",
    "ica.fit(raw, picks=picks, decim=decim, reject=reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search EOG artifacts and exclude those\n",
    "\n",
    "eog_average = create_eog_epochs(raw, reject=reject, picks=picks).average()\n",
    "eog_epochs = create_eog_epochs(raw, reject=reject)  # get single EOG trials\n",
    "eog_inds, scores = ica.find_bads_eog(eog_epochs, threshold = 2) # find via correlation\n",
    "\n",
    "# Plot ICA\n",
    "ica.plot_scores(scores, exclude=eog_inds)        # look at r scores of components\n",
    "ica.plot_sources(eog_average, exclude=eog_inds)  # look at source time course\n",
    "ica.plot_overlay(eog_average, exclude=eog_inds, show=False)\n",
    "                    \n",
    "ica.exclude.extend(eog_inds)\n",
    "del eog_inds, scores, eog_epochs, eog_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study rest of the components manually\n",
    "ica.plot_components(inst = raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding buffer. PLEASE MAKE EDITS HERE BEFORE RUNNING ica.exclude.extend(exclude_list)\n",
    "exclude_list = [] # List bad components here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude other bad components here and plot all the components once again\n",
    "ica.exclude.extend(exclude_list)\n",
    "ica.plot_components(inst = raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ICA to folder ICA.\n",
    "\n",
    "if filename[6] == '.':\n",
    "    ica.save('ICA/' + filename[:6] + '-ica.fif')\n",
    "    print('ICA solution saved for subject: ' + filename[:6])\n",
    "else:\n",
    "    ica.save('ICA/' + filename[:8] + '-ica.fif')\n",
    "    print('ICA solution saved for subject: ' + filename[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed download ICA from folder ICA\n",
    "if filename[6] == '.':\n",
    "    ica = mne.preprocessing.read_ica('ICA/' + filename[:6] + '-ica.fif')\n",
    "else:\n",
    "    ica = mne.preprocessing.read_ica('ICA/' + filename[:8] + '-ica.fif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICA to cropped, filtered and interpolated data\n",
    "\n",
    "ica.apply(raw)\n",
    "ica.plot_overlay(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how preprossing went\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data to folder preprocessed\n",
    "if filename[6] == '.':\n",
    "    raw.save('preprocessed/' + filename[:6] + '-raw.fif', overwrite = True)\n",
    "    print('Preprocessed data saved for subject: ' + filename[:6])\n",
    "else:\n",
    "    raw.save('preprocessed/' + filename[:8] + '-raw.fif', overwrite = True)\n",
    "    print('Preprocessed data saved for subject: ' + filename[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All measurements should be now processed and saved to preprocessed-folder before moving any further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loop processes all the measurements at once\n",
    "\n",
    "for filename in vhdr_files:\n",
    "    \n",
    "    ## Find response path and keyboard_opinion files fron opinion test\n",
    "    response_path = os.path.join(os.getcwd(), 'keyboard_opinion')\n",
    "    response_file = [f for f in os.listdir(response_path) if f.startswith(filename[:6])]\n",
    "    response = response_file[0]\n",
    "\n",
    "\n",
    "    df = pd.read_csv('keyboard_opinion/' + response)\n",
    "    #print(df.head())\n",
    "\n",
    "    # Save disagrees and neutrals to lists\n",
    "    if filename[6] == '.':\n",
    "        disagrees = list(df['disagree_en'])\n",
    "        neutrals = list(df['neutral_en'])\n",
    "    else:\n",
    "        disagrees = list(df['disagree_fin'])\n",
    "        neutrals = list(df['neutral_fin'])\n",
    "\n",
    "        \n",
    "    # Read unknown brands\n",
    "    df = pd.read_csv('unknown/unknown_dataframe.csv')\n",
    "    #print(df.head())\n",
    "\n",
    "    unknow = list(df[str(filename[:6])])\n",
    "    unknow = [x for x in unknow if ~np.isnan(x)] # Drop NaNs\n",
    "    if filename[6] == '.':\n",
    "        unknow.extend(list(df[str(filename[:6]) + '_ad']))\n",
    "    unknow = [x for x in unknow if ~np.isnan(x)] # Drop NaNs\n",
    "\n",
    "    # First sublist contains dislikes and second favourite\n",
    "    # First element (list) at dislike/favourite sublist is matching and second conflicting\n",
    "    # If value is NaN there is no values\n",
    "    # Neutrals are skipped\n",
    "    \n",
    "    # IDs, e.g. 990291 presents that subjects English test and 990291_F Finnish test\n",
    "    favourite_dict = { '990291': [[[125],[185]],[[np.nan],[np.nan]]], '990291_F': [[[np.nan],[np.nan]],[[np.nan],[np.nan]]], \n",
    "                      '928376': [[[np.nan],[np.nan]],[[156, 158],[216, 218]]], '928376_F': [[[np.nan],[np.nan]],[[156, 158],[216, 218]]], \n",
    "                      '884723': [[[125, 185],[np.nan]],[[np.nan],[np.nan]]], '884723_F': [[[125],[185]],[[np.nan],[np.nan]]], \n",
    "                      '554432': [[[145],[206]],[[19, 27, 173],[79, 87, 233]]], '554432_F': [[[145],[206]],[[19, 27],[79, 87]]],\n",
    "                      '477819': [[[np.nan],[np.nan]],[[145, 151],[205, 211]]], '477819_F': [[[np.nan],[np.nan]],[[145, 151, 205],[211]]],\n",
    "                      '382733': [[[121],[181]],[[7],[67]]], '382733_F': [[[np.nan],[121, 181]],[[7],[67]]]\n",
    "                    }\n",
    "\n",
    "    if filename[6] == '.':\n",
    "        ID_dict = filename[:6] + '_F'\n",
    "    else:\n",
    "        ID_dict = filename[:6]\n",
    "\n",
    "    temp_list = favourite_dict[ID_dict]\n",
    "\n",
    "    dislike_match = temp_list[0][0]\n",
    "    dislike_conf = temp_list[0][1]\n",
    "    favo_match = temp_list[1][0]\n",
    "    favo_conf = temp_list[1][1]\n",
    "\n",
    "\n",
    "    # Find and read preprocessed data\n",
    "    if filename[6] == '.':\n",
    "        data_file = 'preprocessed/' + filename[:6] +'-raw.fif'\n",
    "    else:\n",
    "        data_file = 'preprocessed/' + filename[:8] +'-raw.fif'\n",
    "    raw = mne.io.read_raw_fif(data_file, preload=True)\n",
    "\n",
    "    # Give event_IDs to groups (stimuli uses event_IDs 1-240)\n",
    "    event_id = {'Finnish Match': 241, 'Finnish Conf': 242,\n",
    "                'Foreing Match': 243, 'Foreing Conf': 244, \n",
    "                'Neutrals': 245, 'Favourite Match': 246,\n",
    "                'Favourite Conf': 247, 'Dislike Match': 248,\n",
    "                'Dislike Conf': 249, 'Unknowns': 250}\n",
    "\n",
    "    # Set parameters for epochs\n",
    "    tmin, tmax = -0.2, 0.7\n",
    "    baseline = (-0.2, 0)\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False)   \n",
    "\n",
    "    \n",
    "    # Help function for event grouping\n",
    "    def check_if_in(value, answers):\n",
    "        if value in answers:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Search events\n",
    "    events = mne.find_events(raw, stim_channel='STI 014')\n",
    "\n",
    "    \n",
    "    # Process events\n",
    "    i = 0\n",
    "    for value in events[:, 2]:\n",
    "        if value in unknow: # Exclude unknown brands\n",
    "            events[i, 2] = 250\n",
    "        elif value in favo_match:\n",
    "            events[i, 2] = 246\n",
    "        elif value in favo_conf:\n",
    "            events[i, 2] = 247\n",
    "        elif value in dislike_match:\n",
    "            events[i, 2] = 248\n",
    "        elif value in dislike_conf:\n",
    "            events[i, 2] = 249\n",
    "        elif value <=60:    # Finnish matchings\n",
    "            events[i, 2] = 242 if check_if_in(value, disagrees) else 245 if check_if_in(value, neutrals) else 241\n",
    "        elif value <=120: # Finnish conflicting\n",
    "            events[i, 2] = 241 if check_if_in(value, disagrees) else 245 if check_if_in(value, neutrals) else 242\n",
    "        elif value <=180: # Foreing matchings\n",
    "            events[i, 2] = 244 if check_if_in(value, disagrees) else 245 if check_if_in(value, neutrals) else 243\n",
    "        elif 180 < value and value <=240: # Foreing conflicting\n",
    "            events[i, 2] = 243 if check_if_in(value, disagrees) else 245 if check_if_in(value, neutrals) else 244\n",
    "        else:\n",
    "            raise ValueError('WRONG TRIGGER VALUE')    \n",
    "        i += 1\n",
    "\n",
    "    #print(events)\n",
    "    if str(favo_match[0]) == 'nan':\n",
    "        del event_id['Favourite Match']\n",
    "        print('No favourite matching stimuli')\n",
    "    if str(favo_conf[0]) == 'nan':\n",
    "        del event_id['Favourite Conf']\n",
    "        print('No favourite conflicting stimuli')\n",
    "    if str(dislike_match[0]) == 'nan':\n",
    "        del event_id['Dislike Match']\n",
    "        print('No dislike matching stimuli')\n",
    "    if str(dislike_conf[0]) == 'nan':\n",
    "        del event_id['Dislike Conf']\n",
    "        print('No dislike conflicting stimuli')\n",
    "\n",
    "    # Make epochs\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin= tmin, tmax = tmax, preload= True, baseline=baseline, picks=picks)\n",
    "    print('Number of events:', len(events))\n",
    "    print('Unique event codes:', np.unique(events[:, 2]))\n",
    "\n",
    "    # Save epochs to folder processed_epochs\n",
    "    if filename[6] == '.':\n",
    "        epochs.save('processed_epochs/' + filename[:6] + '-epo.fif')\n",
    "        print('Epoch data saved for subject: ' + filename[:6])\n",
    "    else:\n",
    "        epochs.save('processed_epochs/' + filename[:8] + '-epo.fif')\n",
    "        print('Epoch data saved for subject: ' + filename[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed read epochs\n",
    "\n",
    "for filename in vhdr_files:\n",
    "    if filename[6] == '.':\n",
    "        epochs = mne.read_epochs('processed_epochs/' + filename[:6] + '-epo.fif')\n",
    "\n",
    "    else:\n",
    "        epochs = mne.read_epochs('processed_epochs/' + filename[:8] + '-epo.fif')\n",
    "    print(epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
